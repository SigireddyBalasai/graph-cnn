{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from graph_cnn.graph import create_final_graph\n",
    "import networkx as nx\n",
    "from graph_cnn.model import create_model \n",
    "import tensorflow as tf\n",
    "from graph_cnn.graph import mutate\n",
    "from graph_cnn.individual import Individual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g1 = create_final_graph(5,0.8)\n",
    "nx.draw(g1, with_labels=True)\n",
    "plt.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.draw(g1, with_labels=True)\n",
    "plt.draw()\n",
    "g1.edges(data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g1.nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''import numpy as np\n",
    "import random\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "#import minst dataset and split to test trin\n",
    "mnist_dataset, mnist_info = tfds.load(name='crema_d', with_info=True, as_supervised=True)\n",
    "\n",
    "def scale(waveform, label):\n",
    "    waveform = tf.cast(waveform,tf.float64)\n",
    "    spectrogram = tf.signal.stft(\n",
    "    waveform, frame_length=255, frame_step=28)\n",
    "    spectrogram = tf.abs(spectrogram)\n",
    "    spectrogram = spectrogram[..., tf.newaxis]\n",
    "    spectrogram = tf.image.resize(spectrogram,(28,28))\n",
    "    label = tf.one_hot(label, 6)\n",
    "    return spectrogram, label\n",
    "\n",
    "train_data = mnist_dataset['train'].map(scale)\n",
    "test_data = mnist_dataset['test'].map(scale)\n",
    "train_image , train_label = next(iter(train_data.batch(1)))\n",
    "\n",
    "train_ds = train_data.shuffle(10).cache().prefetch(10).batch(64)\n",
    "test_ds = test_data.cache().prefetch(10).batch(64)\n",
    "\n",
    "print(train_image.shape)\n",
    "print(train_label.shape)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "mnist_dataset , mnist_info = tfds.load(name='mnist', with_info=True, as_supervised=True,split=['train', 'test[:50%]'],shuffle_files=True)\n",
    "train_data = mnist_dataset[0]\n",
    "test_data = mnist_dataset[1]\n",
    "def scale(image, label):\n",
    "    image = tf.cast(image,tf.float64)\n",
    "    image = tf.image.resize(image,(28,28))\n",
    "    image = image/225\n",
    "    label = tf.one_hot(label, 10)\n",
    "    return image, label\n",
    "train_data = train_data.map(scale)\n",
    "test_data = test_data.map(scale)\n",
    "train_ds = train_data.cache().batch(64).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "test_ds = test_data.cache().batch(64).prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''!pip install -q opendatasets\n",
    "\n",
    "import opendatasets as od\n",
    "import pandas as pd\n",
    "\n",
    "od.download('https://www.kaggle.com/datasets/puneet6060/intel-image-classification')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''import tensorflow as tf\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "\n",
    "class CustomImageDataGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(self, directory, batch_size=28, image_size=(128, 128), shuffle=True):\n",
    "        self.directory = directory\n",
    "        self.batch_size = batch_size\n",
    "        self.image_size = image_size\n",
    "        self.shuffle = shuffle\n",
    "        self.filepaths = self._get_filepaths()\n",
    "        self.indexes = np.arange(len(self.filepaths))\n",
    "        self.class_mapping = self._create_class_mapping()\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def _get_filepaths(self):\n",
    "        pattern = os.path.join(self.directory, '*/*.jpg')  # Assuming PNG format, modify as needed\n",
    "        filepaths = glob.glob(pattern)\n",
    "        random.shuffle(filepaths)\n",
    "        return filepaths\n",
    "\n",
    "    def _create_class_mapping(self):\n",
    "        classes = sorted(set(os.listdir(self.directory)))\n",
    "        print(len(classes))\n",
    "        class_mapping = {cls: idx for idx, cls in enumerate(classes)}\n",
    "        return class_mapping\n",
    "\n",
    "    def _load_and_preprocess_image(self, filepath):\n",
    "        image = tf.keras.preprocessing.image.load_img(filepath, target_size=self.image_size, color_mode='grayscale')\n",
    "        image = tf.keras.preprocessing.image.img_to_array(image)\n",
    "        datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=True\n",
    "        )\n",
    "        image = image.reshape((1,) + image.shape)\n",
    "        augmented_image = datagen.flow(image).next()[0]\n",
    "        image = augmented_image / 255.0  # Normalize to [0, 1]\n",
    "        return image\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.filepaths) / self.batch_size))\n",
    "\n",
    "    def _downsample(self, batch_images, batch_labels):\n",
    "        unique_labels, label_counts = np.unique(batch_labels.argmax(axis=1), return_counts=True)\n",
    "        min_label_count = np.min(label_counts)\n",
    "\n",
    "        downsampled_images = []\n",
    "        downsampled_labels = []\n",
    "\n",
    "        for label in unique_labels:\n",
    "            label_indices = np.where(batch_labels.argmax(axis=1) == label)[0]\n",
    "            selected_indices = np.random.choice(label_indices, size=min_label_count, replace=False)\n",
    "\n",
    "            downsampled_images.extend(batch_images[selected_indices])\n",
    "            downsampled_labels.extend(batch_labels[selected_indices])\n",
    "\n",
    "        downsampled_images = np.array(downsampled_images)\n",
    "        downsampled_labels = np.array(downsampled_labels)\n",
    "\n",
    "        # Shuffle the downsampled data\n",
    "        shuffle_indices = np.arange(len(downsampled_labels))\n",
    "        np.random.shuffle(shuffle_indices)\n",
    "\n",
    "        return downsampled_images[shuffle_indices], downsampled_labels[shuffle_indices]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        batch_filepaths = self.filepaths[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        batch_images = []\n",
    "        batch_labels = []\n",
    "\n",
    "        for filepath in batch_filepaths:\n",
    "            image = self._load_and_preprocess_image(filepath)\n",
    "            label_str = os.path.basename(os.path.dirname(filepath))\n",
    "            label = self.class_mapping[label_str]\n",
    "            label = tf.keras.utils.to_categorical(label,6)\n",
    "\n",
    "            batch_images.append(image)\n",
    "            batch_labels.append(label)\n",
    "\n",
    "        batch_images = np.array(batch_images)\n",
    "        batch_labels = np.array(batch_labels)\n",
    "        \n",
    "        batch_images, batch_labels = self._downsample(batch_images, batch_labels)\n",
    "\n",
    "        return batch_images, batch_labels\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "# Example usage:\n",
    "train_generator = CustomImageDataGenerator(directory='intel-image-classification/seg_train/seg_train', batch_size=512)\n",
    "test_generator = CustomImageDataGenerator(directory='intel-image-classification/seg_test/seg_test', batch_size=512)\n",
    "\n",
    "# Rest of the code remains the same...\n",
    "\n",
    "\n",
    "train_ds = tf.data.Dataset.from_generator(\n",
    "    generator=lambda: train_generator,\n",
    "    output_signature=(\n",
    "        tf.TensorSpec(shape=(None,128,128,1), dtype=tf.float28),\n",
    "        tf.TensorSpec(shape=(None,6), dtype=tf.float28),\n",
    "    )\n",
    ").cache()\n",
    "\n",
    "test_ds = tf.data.Dataset.from_generator(\n",
    "    generator=lambda: test_generator,\n",
    "    output_signature=(\n",
    "        tf.TensorSpec(shape=(None,128,128,1), dtype=tf.float28),\n",
    "        tf.TensorSpec(shape=(None,6), dtype=tf.float28),\n",
    "    )\n",
    ").cache()\n",
    "\n",
    "for epoch in range(5):\n",
    "    for batch_x, batch_y in test_ds:\n",
    "        print(batch_x.shape)\n",
    "        print(batch_y.shape)\n",
    "        print(batch_y)\n",
    "        break'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model(g1,(28,28,1),10,include_aux=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.SGD(0.001), loss=tf.keras.losses.CategoricalCrossentropy(), metrics=[tf.keras.metrics.CategoricalAccuracy(),\n",
    "                                                                                                               tf.keras.metrics.AUC(from_logits=True),\n",
    "                                                                                                               #tf.keras.metrics.Precision(),\n",
    "                                                                                                               #tf.keras.metrics.Recall()\n",
    "                                                                                                               ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(model, to_file='model.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''g1 = create_random_graph(5,0.5)\n",
    "g1 = assign_states(g1,(1,3,1))\n",
    "fig , ax = plt.subplots(2,1)\n",
    "g3 = mutate_dag(g1)\n",
    "nx.draw(g1, with_labels=True, ax=ax[0])\n",
    "nx.draw(g3, with_labels=True, ax=ax[1])\n",
    "plt.draw()'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''g4 = crossover(g1,g3)\n",
    "fig , ax = plt.subplots(2,1)\n",
    "nx.draw(g1, with_labels=True, ax=ax[0])\n",
    "nx.draw(g4, with_labels=True, ax=ax[1])\n",
    "plt.draw()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/938 [===>..........................] - ETA: 14:32 - loss: 2.3412 - categorical_accuracy: 0.1022 - auc: 0.4945"
     ]
    }
   ],
   "source": [
    "model.fit(train_ds, epochs=10, validation_data=test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from IPython.display import clear_output\n",
    "\n",
    "class ClassificationMatrixCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        clear_output(wait=True)\n",
    "        y_pred =  np.array(self.model.predict(test_ds))\n",
    "        print(y_pred.shape)\n",
    "        if len(y_pred.shape) == 3:\n",
    "            y_pred = y_pred[0]\n",
    "        predicted_labels = np.argmax(y_pred, axis=1)\n",
    "        true_labels = np.concatenate([y for x, y in test_ds], axis=0)\n",
    "        print(true_labels.shape,predicted_labels.shape)\n",
    "        true_labels = np.argmax(true_labels,axis=-1)\n",
    "        cm = confusion_matrix(true_labels, predicted_labels)\n",
    "        print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.legacy.Adam(learning_rate=0.001)\n",
    "\n",
    "class_names = ['angry', 'disgust', 'fear', 'happy', 'sad', 'surprise', 'neutral']\n",
    "class_names = ['0','1','2','3','4','5','6','7','8','9']\n",
    "callback = [ClassificationMatrixCallback(),\n",
    "            #tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3),\n",
    "            tf.keras.callbacks.ReduceLROnPlateau(monitor='loss', factor=0.1, patience=5),\n",
    "            tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=10),]\n",
    "metrics = [tf.keras.metrics.AUC(from_logits=True),tf.keras.metrics.CategoricalAccuracy(),tf.keras.metrics.Precision(),tf.keras.metrics.Recall(),tf.keras.metrics.AUC(name='prc', curve='PR')]\n",
    "model.compile(optimizer=optimizer, loss=tf.keras.losses.CategoricalCrossentropy(),metrics=[\n",
    "                                                                                            tf.keras.metrics.Accuracy(),\n",
    "                                                                                            tf.keras.metrics.AUC(from_logits=True),\n",
    "                                                                                            tf.keras.metrics.CategoricalAccuracy(),\n",
    "                                                                                            #tf.keras.metrics.Precision(),\n",
    "                                                                                            #tf.keras.metrics.Recall(),\n",
    "                                                                                            tf.keras.metrics.AUC(name='prc', curve='PR'),\n",
    "                                                                                            ]\n",
    "                                                                                            )\n",
    "model.summary()\n",
    "class_names = ['0','1','2','3','4','5','6','7','8','9']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(model, to_file='model.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_ds,validation_data=test_ds, epochs=30,\n",
    "          #steps_per_epoch=50,\n",
    "           callbacks=[callback],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "from graph_cnn.generation.generate import Generation\n",
    "ga = Generation(input_size=(128,128,1),output_size=(102),nodes=13\n",
    ",edges=0.8,population=17,limit=18,train_ds=train_ds,test_ds=test_ds,optimizer=optimizer,loss=loss,metrics=metrics,callbacks=callback)\n",
    "ga.run(10,0.8,0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
