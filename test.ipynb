{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from graph_cnn.graph import create_final_graph\n",
    "import networkx as nx\n",
    "from graph_cnn.model import create_model \n",
    "import tensorflow as tf\n",
    "from graph_cnn.graph import mutate\n",
    "from graph_cnn.individual import Individual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g1 = create_final_graph(15,0.8)\n",
    "nx.draw(g1, with_labels=True)\n",
    "plt.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.draw(g1, with_labels=True)\n",
    "plt.draw()\n",
    "g1.edges(data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g1.nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''import numpy as np\n",
    "import random\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "#import minst dataset and split to test trin\n",
    "mnist_dataset, mnist_info = tfds.load(name='crema_d', with_info=True, as_supervised=True)\n",
    "\n",
    "def scale(waveform, label):\n",
    "    waveform = tf.cast(waveform,tf.float64)\n",
    "    spectrogram = tf.signal.stft(\n",
    "    waveform, frame_length=255, frame_step=128)\n",
    "    spectrogram = tf.abs(spectrogram)\n",
    "    spectrogram = spectrogram[..., tf.newaxis]\n",
    "    spectrogram = tf.image.resize(spectrogram,(128,128))\n",
    "    label = tf.one_hot(label, 6)\n",
    "    return spectrogram, label\n",
    "\n",
    "train_data = mnist_dataset['train'].map(scale)\n",
    "test_data = mnist_dataset['test'].map(scale)\n",
    "train_image , train_label = next(iter(train_data.batch(1)))\n",
    "\n",
    "train_ds = train_data.shuffle(10).cache().prefetch(10).batch(64)\n",
    "test_ds = test_data.cache().prefetch(10).batch(64)\n",
    "\n",
    "print(train_image.shape)\n",
    "print(train_label.shape)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "mnist_dataset , mnist_info = tfds.load(name='mnist', with_info=True, as_supervised=True,split=['train', 'test[:50%]'])\n",
    "train_data = mnist_dataset[0]\n",
    "test_data = mnist_dataset[1]\n",
    "def scale(image, label):\n",
    "    image = tf.cast(image,tf.float64)\n",
    "    image = image/255\n",
    "    label = tf.one_hot(label, 10)\n",
    "    return image, label\n",
    "train_data = train_data.map(scale)\n",
    "test_data = test_data.map(scale)\n",
    "train_ds = train_data.cache().batch(64).prefetch(10)\n",
    "test_ds = test_data.cache().batch(64).prefetch(10)\n",
    "train_image , train_label = next(iter(train_data.batch(1)))\n",
    "print(train_image.shape)\n",
    "print(train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q opendatasets\n",
    "\n",
    "import opendatasets as od\n",
    "import pandas as pd\n",
    "\n",
    "od.download('https://www.kaggle.com/datasets/puneet6060/intel-image-classification')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "\n",
    "class CustomImageDataGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(self, directory, batch_size=32, image_size=(128, 128), shuffle=True):\n",
    "        self.directory = directory\n",
    "        self.batch_size = batch_size\n",
    "        self.image_size = image_size\n",
    "        self.shuffle = shuffle\n",
    "        self.filepaths = self._get_filepaths()\n",
    "        self.indexes = np.arange(len(self.filepaths))\n",
    "        self.class_mapping = self._create_class_mapping()\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def _get_filepaths(self):\n",
    "        pattern = os.path.join(self.directory, '*/*.jpg')  # Assuming PNG format, modify as needed\n",
    "        filepaths = glob.glob(pattern)\n",
    "        random.shuffle(filepaths)\n",
    "        return filepaths\n",
    "\n",
    "    def _create_class_mapping(self):\n",
    "        classes = sorted(set(os.listdir(self.directory)))\n",
    "        print(len(classes))\n",
    "        class_mapping = {cls: idx for idx, cls in enumerate(classes)}\n",
    "        return class_mapping\n",
    "\n",
    "    def _load_and_preprocess_image(self, filepath):\n",
    "        image = tf.keras.preprocessing.image.load_img(filepath, target_size=self.image_size, color_mode='grayscale')\n",
    "        image = tf.keras.preprocessing.image.img_to_array(image)\n",
    "        datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=True\n",
    "        )\n",
    "        image = image.reshape((1,) + image.shape)\n",
    "        augmented_image = datagen.flow(image).next()[0]\n",
    "        image = augmented_image / 255.0  # Normalize to [0, 1]\n",
    "        return image\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.filepaths) / self.batch_size))\n",
    "\n",
    "    def _downsample(self, batch_images, batch_labels):\n",
    "        unique_labels, label_counts = np.unique(batch_labels.argmax(axis=1), return_counts=True)\n",
    "        min_label_count = np.min(label_counts)\n",
    "\n",
    "        downsampled_images = []\n",
    "        downsampled_labels = []\n",
    "\n",
    "        for label in unique_labels:\n",
    "            label_indices = np.where(batch_labels.argmax(axis=1) == label)[0]\n",
    "            selected_indices = np.random.choice(label_indices, size=min_label_count, replace=False)\n",
    "\n",
    "            downsampled_images.extend(batch_images[selected_indices])\n",
    "            downsampled_labels.extend(batch_labels[selected_indices])\n",
    "\n",
    "        downsampled_images = np.array(downsampled_images)\n",
    "        downsampled_labels = np.array(downsampled_labels)\n",
    "\n",
    "        # Shuffle the downsampled data\n",
    "        shuffle_indices = np.arange(len(downsampled_labels))\n",
    "        np.random.shuffle(shuffle_indices)\n",
    "\n",
    "        return downsampled_images[shuffle_indices], downsampled_labels[shuffle_indices]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        batch_filepaths = self.filepaths[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        batch_images = []\n",
    "        batch_labels = []\n",
    "\n",
    "        for filepath in batch_filepaths:\n",
    "            image = self._load_and_preprocess_image(filepath)\n",
    "            label_str = os.path.basename(os.path.dirname(filepath))\n",
    "            label = self.class_mapping[label_str]\n",
    "            label = tf.keras.utils.to_categorical(label,6)\n",
    "\n",
    "            batch_images.append(image)\n",
    "            batch_labels.append(label)\n",
    "\n",
    "        batch_images = np.array(batch_images)\n",
    "        batch_labels = np.array(batch_labels)\n",
    "        \n",
    "        batch_images, batch_labels = self._downsample(batch_images, batch_labels)\n",
    "\n",
    "        return batch_images, batch_labels\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "# Example usage:\n",
    "train_generator = CustomImageDataGenerator(directory='intel-image-classification/seg_train/seg_train', batch_size=512)\n",
    "test_generator = CustomImageDataGenerator(directory='intel-image-classification/seg_test/seg_test', batch_size=512)\n",
    "\n",
    "# Rest of the code remains the same...\n",
    "\n",
    "\n",
    "train_ds = tf.data.Dataset.from_generator(\n",
    "    generator=lambda: train_generator,\n",
    "    output_signature=(\n",
    "        tf.TensorSpec(shape=(None,128,128,1), dtype=tf.float32),\n",
    "        tf.TensorSpec(shape=(None,6), dtype=tf.float32),\n",
    "    )\n",
    ").cache()\n",
    "\n",
    "test_ds = tf.data.Dataset.from_generator(\n",
    "    generator=lambda: test_generator,\n",
    "    output_signature=(\n",
    "        tf.TensorSpec(shape=(None,128,128,1), dtype=tf.float32),\n",
    "        tf.TensorSpec(shape=(None,6), dtype=tf.float32),\n",
    "    )\n",
    ").cache()\n",
    "\n",
    "for epoch in range(5):\n",
    "    for batch_x, batch_y in test_ds:\n",
    "        print(batch_x.shape)\n",
    "        print(batch_y.shape)\n",
    "        print(batch_y)\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model(g1,(28,28,1),10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.compile(optimizer='adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=[tf.keras.metrics.SparseCategoricalAccuracy(),\n",
    "                                                                                                               #tf.keras.metrics.AUC(from_logits=True),\n",
    "                                                                                                               #tf.keras.metrics.Precision(),\n",
    "                                                                                                               #tf.keras.metrics.Recall()\n",
    "                                                                                                               ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(model, to_file='model.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''g1 = create_random_graph(5,0.5)\n",
    "g1 = assign_states(g1,(1,3,1))\n",
    "fig , ax = plt.subplots(2,1)\n",
    "g3 = mutate_dag(g1)\n",
    "nx.draw(g1, with_labels=True, ax=ax[0])\n",
    "nx.draw(g3, with_labels=True, ax=ax[1])\n",
    "plt.draw()'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''g4 = crossover(g1,g3)\n",
    "fig , ax = plt.subplots(2,1)\n",
    "nx.draw(g1, with_labels=True, ax=ax[0])\n",
    "nx.draw(g4, with_labels=True, ax=ax[1])\n",
    "plt.draw()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in1 = Individual((128,128,1),(6),5,0.6)\n",
    "tf.keras.utils.plot_model(in1.model, to_file='model.png', show_shapes=True)\n",
    "model = in1.model\n",
    "#visualkeras.layered_view(model, to_file='output.png').show() # view model structure in jupyter (suggested)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_val, y_test_val = [], []\n",
    "for x, y in test_ds.as_numpy_iterator():\n",
    "    x_test_val.append(x)\n",
    "    y_test_val.append(y)\n",
    "x_test_val = np.concatenate(x_test_val)\n",
    "y_test_val = np.concatenate(y_test_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "class ClassificationMatrixCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, x_test_val,y_test_val, class_names):\n",
    "        super(ClassificationMatrixCallback, self).__init__()\n",
    "        self.x_val = x_test_val\n",
    "        self.y_val = y_test_val\n",
    "        self.class_names = class_names\n",
    "\n",
    "    def on_epoch_end(self, step, logs=None):\n",
    "            y_pred = np.argmax(self.model.predict(self.x_val), axis=1)\n",
    "            y_true = np.argmax(self.y_val, axis=1)\n",
    "            cm = confusion_matrix(y_true, y_pred)\n",
    "            plt.figure(figsize=(8, 6))\n",
    "            sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=self.class_names, yticklabels=self.class_names)\n",
    "            plt.title('Classification Matrix')\n",
    "            plt.xlabel('Predicted')\n",
    "            plt.ylabel('True')\n",
    "            plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.legacy.Adam(learning_rate=0.001)\n",
    "\n",
    "class_names = ['angry', 'disgust', 'fear', 'happy', 'sad', 'surprise', 'neutral']\n",
    "class_names = ['0','1','2','3','4','5','6','7','8','9']\n",
    "callback = [ClassificationMatrixCallback(x_test_val,y_test_val,class_names),\n",
    "            #tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3),\n",
    "            tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=2)]\n",
    "metrics = [tf.keras.metrics.AUC(from_logits=True),tf.keras.metrics.CategoricalAccuracy(),tf.keras.metrics.Precision(),tf.keras.metrics.Recall(),tf.keras.metrics.AUC(name='prc', curve='PR')]\n",
    "model.compile(optimizer=optimizer, loss=tf.keras.losses.CategoricalCrossentropy(),metrics=[\n",
    "                                                                                            tf.keras.metrics.Accuracy(),\n",
    "                                                                                            tf.keras.metrics.AUC(from_logits=True),\n",
    "                                                                                            tf.keras.metrics.CategoricalAccuracy(),\n",
    "                                                                                            #tf.keras.metrics.Precision(),\n",
    "                                                                                            #tf.keras.metrics.Recall(),\n",
    "                                                                                            tf.keras.metrics.AUC(name='prc', curve='PR'),\n",
    "                                                                                            ]\n",
    "                                                                                            )\n",
    "model.summary()\n",
    "class_names = ['0','1','2','3','4','5','6','7','8','9']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(model, to_file='model.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_ds,validation_data=test_ds, epochs=3000,\n",
    "          #steps_per_epoch=50,\n",
    "           callbacks=[callback],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "ga = Generation(input_size=(48,48,1),output_size=(7),states=(1,1,1,1,1,1),nodes=3\n",
    ",edges=0.8,population=7,limit=18,train_ds=train_ds,test_ds=test_ds,optimizer=optimizer,loss=loss,metrics=metrics,callbacks=callback)\n",
    "ga.run(10,0.8,0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
