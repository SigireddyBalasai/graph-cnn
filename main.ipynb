{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graph_cnn.model import create_model\n",
    "from graph_cnn.graph import create_final_graph,cross_over\n",
    "import networkx as nx\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_ = create_final_graph(5,0.7)\n",
    "print(graph_)\n",
    "nx.draw(graph_,with_labels=True)\n",
    "plt.show()\n",
    "model = create_model(graph_,input_shape=(28,28,1),num_classes=10)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, info = tfds.load('mnist', split='train', with_info=True, as_supervised=True, shuffle_files=True)\n",
    "test_dataset = tfds.load('mnist', split='test', as_supervised=True, shuffle_files=True)\n",
    "\n",
    "# Print dataset information\n",
    "print(info)\n",
    "\n",
    "train_dataset = train_dataset.cache().shuffle(1000).batch(128).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "test_dataset = test_dataset.cache().shuffle(1000).batch(128).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "for i,j in train_dataset:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer = tf.keras.layers.Input(shape=(28, 28, 1))\n",
    "#random_flip = tf.keras.layers.RandomFlip(\"horizontal\")(input_layer)\n",
    "#random_rotation = tf.keras.layers.RandomRotation(0.2)(random_flip)\n",
    "#random_zoom = tf.keras.layers.RandomZoom(0.2)(random_rotation)\n",
    "#gaussian_noise = tf.keras.layers.GaussianNoise(0.3)(random_zoom)\n",
    "rescaling = tf.keras.layers.Rescaling(1./255)(input_layer)\n",
    "output = model(rescaling)\n",
    "\n",
    "model2 = tf.keras.models.Model(inputs=input_layer, outputs=output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "METRICS = [\n",
    "      tf.keras.metrics.CategoricalAccuracy(name='accuracy'),\n",
    "      #tf.keras.metrics.Precision(name='precision'),\n",
    "      #tf.keras.metrics.Recall(name='recall'),\n",
    "      #tf.keras.metrics.AUC(name='auc'),\n",
    "      #tf.keras.metrics.TruePositives(name='tp'),\n",
    "      #tf.keras.metrics.TrueNegatives(name='tn'),\n",
    "      #tf.keras.metrics.FalsePositives(name='fp'),\n",
    "      #tf.keras.metrics.FalseNegatives(name='fn'),\n",
    "      #tf.keras.metrics.AUC(name='prc', curve='PR'), # precision-recall curve\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.compile(optimizer=tf.keras.optimizers.Adam(0.0001),loss=tf.keras.losses.SparseCategoricalCrossentropy(),metrics=METRICS)\n",
    "model2.summary()\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2,patience=10,min_delta=0.01, min_lr=0)\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
    "class DisplayCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        clear_output(wait=True)\n",
    "        y_pred =  np.array(self.model.predict(test_dataset))[0]\n",
    "        predicted_labels = np.argmax(y_pred, axis=1)\n",
    "        true_labels = np.concatenate([y for x, y in test_dataset], axis=0)\n",
    "        cm = confusion_matrix(true_labels, predicted_labels)\n",
    "        print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(model2, to_file=\"model.png\", show_shapes=True, show_layer_names=True, rankdir=\"TB\", expand_nested=True, dpi=96)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''model2=tf.keras.applications.densenet.DenseNet121(include_top=False, weights=None, input_shape=(36,36,3), pooling=None, classes=10)\n",
    "model = tf.keras.models.Sequential([\n",
    "    model2,\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(10, activation='softmax'),\n",
    "])\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(0.001),loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),metrics=['accuracy'])\n",
    "model.summary()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on the test dataset\n",
    "predictions = model2.predict(test_dataset)\n",
    "predictions = np.array(predictions)[0]\n",
    "# Get the predicted labels\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Get the true labels\n",
    "true_labels = np.concatenate([y for x, y in test_dataset], axis=0)\n",
    "print(true_labels,predicted_labels.shape)\n",
    "print(true_labels.shape,predicted_labels.shape)\n",
    "\n",
    "# Plot the classification results\n",
    "# Generate the confusion matrix\n",
    "cm = confusion_matrix(true_labels, predicted_labels)\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 28s 357ms/step\n",
      "[[  0 496   4 201  29   0 173  76   0   1]\n",
      " [  0 563   4 238  31   0 216  80   0   3]\n",
      " [  0 501   5 211  33   0 180  96   2   4]\n",
      " [  0 519   3 197  27   0 177  83   1   3]\n",
      " [  0 510   3 188  30   0 173  75   1   2]\n",
      " [  0 455   2 197  17   0 163  57   0   1]\n",
      " [  0 487   5 182  16   0 180  79   1   8]\n",
      " [  0 501   8 212  20   0 202  81   0   4]\n",
      " [  0 502   4 200  26   0 174  65   0   3]\n",
      " [  0 529   7 200  21   1 172  76   2   1]]\n",
      "469/469 [==============================] - 651s 1s/step - loss: 3.9283 - model_loss: 3.0813 - model_1_loss: 0.7103 - model_2_loss: 0.1368 - model_accuracy: 0.0939 - model_1_accuracy: 0.1046 - model_2_accuracy: 0.0991 - val_loss: 5.0636 - val_model_loss: 2.2881 - val_model_1_loss: 2.1962 - val_model_2_loss: 0.5793 - val_model_accuracy: 0.0000e+00 - val_model_1_accuracy: 0.0661 - val_model_2_accuracy: 0.1010 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "113/469 [======>.......................] - ETA: 7:23 - loss: 3.5547 - model_loss: 2.7980 - model_1_loss: 0.6252 - model_2_loss: 0.1315 - model_accuracy: 0.0902 - model_1_accuracy: 0.1067 - model_2_accuracy: 0.1013"
     ]
    }
   ],
   "source": [
    "model2.fit(train_dataset, epochs=100, validation_data=test_dataset,callbacks=[reduce_lr,early_stop,DisplayCallback()])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
